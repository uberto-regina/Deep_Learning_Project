{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbff3e74-b30c-40f0-a784-4a6450521983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Third-Party Libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# Avalanche: Continual Learning Framework\n",
    "## Benchmarks\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.datasets.torchvision_wrapper import CIFAR10\n",
    "from avalanche.benchmarks.scenarios import CLExperience\n",
    "from avalanche.benchmarks.utils.flat_data import ConstantSequence\n",
    "\n",
    "## Models\n",
    "from avalanche.models import (\n",
    "    MultiHeadClassifier,\n",
    "    MultiTaskModule,\n",
    "    MTSimpleMLP,\n",
    "    MTSimpleCNN,\n",
    "    PNN,\n",
    ")\n",
    "\n",
    "## Training Strategies\n",
    "from avalanche.training.supervised import Naive, EWC, LwF\n",
    "\n",
    "## Plugins and Logging\n",
    "from avalanche.logging import InteractiveLogger, TextLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin, LRSchedulerPlugin\n",
    "\n",
    "## Evaluation Metrics\n",
    "from avalanche.evaluation.metrics import (\n",
    "    accuracy_metrics,\n",
    "    forgetting_metrics,\n",
    "    loss_metrics,\n",
    "    timing_metrics,\n",
    "    cpu_usage_metrics,\n",
    "    confusion_matrix_metrics,\n",
    "    disk_usage_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e560ac-eab4-4eab-899c-b6bcf122fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "import os\n",
    "\n",
    "if SAVE:\n",
    "    os.chdir('/home/uregina/DL_Project')\n",
    "    print(os.getcwd())\n",
    "\n",
    "# For saving the datasets/models/results/log files\n",
    "\n",
    "if SAVE:\n",
    "    DATASET_NAME = \"SplitCIFAR10\"\n",
    "    ROOT = Path(\"/home/uregina/DL_Project\")\n",
    "    DATA_ROOT = ROOT / DATASET_NAME\n",
    "    DATA_ROOT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9805e34-39f6-462f-a447-bc01f784b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 0\n",
    "\n",
    "DATASET_NAME = \"SplitCIFAR10\"\n",
    "NUM_CLASSES = {\n",
    "    \"SplitCIFAR10\": 10\n",
    "}\n",
    "\n",
    "# Define hyperparameters/scheduler/augmentation\n",
    "HPARAM = {\n",
    "    \"batch_size\": 128,        #CHANGE\n",
    "    \"num_epoch\": 3,           #CHANGE\n",
    "    \"start_lr\": 0.01,\n",
    "    \"alpha\": 0.7,\n",
    "    \"temperature\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c395a43-550e-43d3-b3c1-607f2808ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        # Adjusting the first Conv2d to take 320 channels as input (from EfficientNet b0 output)\n",
    "        self.features = nn.Sequential(\n",
    "            # First convolution: 320 input channels to 120 output channels (reduce parameters)\n",
    "            nn.Conv2d(192, 120, kernel_size=1, stride=1, padding=0),  # 1x1 kernel reduces parameters\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Second convolution: 128 input channels to 64 output channels (further reduce)\n",
    "            nn.Conv2d(120, 64, kernel_size=1, stride=1, padding=0),  # 1x1 kernel reduces parameters\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Ensure fixed spatial size of 1x1 using AdaptiveAvgPool2d\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Dropout(p=0.25),\n",
    "        )\n",
    "\n",
    "        # Classifier will take the 64 channels (final output from features)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for classifier\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class MTCustomCNN(CustomCNN, MultiTaskModule):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network\n",
    "    with multi-head classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = MultiHeadClassifier(64)\n",
    "\n",
    "\n",
    "    def forward(self, x, task_labels):\n",
    "\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for classifier\n",
    "        x = self.classifier(x, task_labels)\n",
    "        return x\n",
    "\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "class EfficientNetCNN(MultiTaskModule):\n",
    "    def __init__(self):\n",
    "        super(EfficientNetCNN, self).__init__()\n",
    "        # Use the updated `weights` parameter instead of `pretrained`\n",
    "        self.model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        \n",
    "        # Freeze all parameters in the model\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Extract layers up to block 7\n",
    "        self.block7 = nn.Sequential(\n",
    "            *list(self.model.features[:7])  # Extract up to and including block 7\n",
    "        )\n",
    "        \n",
    "        # Custom classifier\n",
    "        self.classifier = MTCustomCNN()\n",
    "\n",
    "        # Freeze EfficientNet parameters\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward_single_task(self, x, task_id):\n",
    "        x = self.block7(x)\n",
    "        out = self.classifier(x, task_id)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7343024a-c520-4acb-8ab2-068f1be8040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# print to stdout\n",
    "interactive_logger = InteractiveLogger()\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "benchmark = SplitCIFAR10(\n",
    "    n_experiences = 5,          #CHANGE\n",
    "    return_task_id = True,\n",
    "    seed=seed,\n",
    "    train_transform=train_transform,\n",
    "    eval_transform=test_transform\n",
    ")\n",
    "\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "    timing_metrics(epoch=True, epoch_running=True),\n",
    "    forgetting_metrics(experience=True, stream=True),\n",
    "    cpu_usage_metrics(experience=True),\n",
    "    confusion_matrix_metrics(\n",
    "        num_classes=NUM_CLASSES[DATASET_NAME], save_image=False, stream=True\n",
    "    ),\n",
    "    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loggers=interactive_logger,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ade9ef1-c728-42f4-b4ae-22451914f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'EfficientNetCNN'\n",
    "RUN = '0'                    #Multiple runs 0,1,2\n",
    "model = EfficientNetCNN()\n",
    "\n",
    "optimizer = Adam(model.parameters(), HPARAM[\"start_lr\"])\n",
    "\n",
    "cl_strategy = LwF(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    train_mb_size=HPARAM[\"batch_size\"],\n",
    "    train_epochs=HPARAM[\"num_epoch\"],\n",
    "    eval_mb_size=HPARAM[\"batch_size\"],\n",
    "    alpha=HPARAM[\"alpha\"],              # LwF parameter\n",
    "    temperature=HPARAM[\"temperature\"],  # LwF parameter\n",
    "    evaluator=eval_plugin,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "if SAVE:\n",
    "    DATA_ROOT = ROOT / DATASET_NAME / MODEL_NAME / RUN\n",
    "    DATA_ROOT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568e039c-8fd0-4cdc-aa61-eb9ef2116efd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience:  0\n",
      "Current Classes:  [1, 4]\n",
      "-- >> Start of training phase << --\n",
      " 10%|â–ˆ         | 8/79 [00:03<00:25,  2.73it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart of experience: \u001b[39m\u001b[38;5;124m\"\u001b[39m, experience\u001b[38;5;241m.\u001b[39mcurrent_experience)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Classes: \u001b[39m\u001b[38;5;124m\"\u001b[39m, experience\u001b[38;5;241m.\u001b[39mclasses_in_this_experience)\n\u001b[0;32m----> 6\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mcl_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing accuracy on the whole test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/training/templates/base_sgd.py:213\u001b[0m, in \u001b[0;36mBaseSGDTemplate.train\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     experiences: Union[TDatasetExperience, Iterable[TDatasetExperience]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    212\u001b[0m ):\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mget_last_metrics()\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/training/templates/base.py:163\u001b[0m, in \u001b[0;36mBaseTemplate.train\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperience \u001b[38;5;129;01min\u001b[39;00m experiences_list:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/training/templates/base_sgd.py:339\u001b[0m, in \u001b[0;36mBaseSGDTemplate._train_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_epoch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/training/templates/update_type/sgd_update.py:19\u001b[0m, in \u001b[0;36mSGDUpdate.training_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtraining_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Training epoch.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    :param kwargs:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stop_training\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/benchmarks/utils/data_loader.py:199\u001b[0m, in \u001b[0;36mMultiDatasetDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_loader\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_loader()\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/torch/utils/data/dataset.py:350\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/benchmarks/utils/data.py:355\u001b[0m, in \u001b[0;36mAvalancheDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m: TAvalancheDataset, idx: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mslice\u001b[39m]\n\u001b[1;32m    354\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[T_co, TAvalancheDataset]:\n\u001b[0;32m--> 355\u001b[0m     elem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m da \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attributes\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    357\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m da\u001b[38;5;241m.\u001b[39muse_in_getitem:\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/benchmarks/utils/data.py:558\u001b[0m, in \u001b[0;36m_FlatDataWithTransform.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28mself\u001b[39m: TDataWTransform, idx: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mslice\u001b[39m]\n\u001b[1;32m    556\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[T_co, TDataWTransform]:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[0;32m--> 558\u001b[0m         elem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_recursive_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m            \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_groups\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_group\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/benchmarks/utils/data.py:544\u001b[0m, in \u001b[0;36m_FlatDataWithTransform._getitem_recursive_call\u001b[0;34m(self, idx, group_name)\u001b[0m\n\u001b[1;32m    542\u001b[0m dd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets[dataset_idx]\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dd, _FlatDataWithTransform):\n\u001b[0;32m--> 544\u001b[0m     element \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_recursive_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m     element \u001b[38;5;241m=\u001b[39m dd[idx]\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/benchmarks/utils/data.py:544\u001b[0m, in \u001b[0;36m_FlatDataWithTransform._getitem_recursive_call\u001b[0;34m(self, idx, group_name)\u001b[0m\n\u001b[1;32m    542\u001b[0m dd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets[dataset_idx]\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dd, _FlatDataWithTransform):\n\u001b[0;32m--> 544\u001b[0m     element \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_recursive_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m     element \u001b[38;5;241m=\u001b[39m dd[idx]\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/benchmarks/utils/data.py:551\u001b[0m, in \u001b[0;36m_FlatDataWithTransform._getitem_recursive_call\u001b[0;34m(self, idx, group_name)\u001b[0m\n\u001b[1;32m    549\u001b[0m     element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frozen_transform_groups(element, group_name\u001b[38;5;241m=\u001b[39mgroup_name)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_groups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 551\u001b[0m     element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m element\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/benchmarks/utils/transform_groups.py:131\u001b[0m, in \u001b[0;36mTransformGroups.__call__\u001b[0;34m(self, group_name, *args)\u001b[0m\n\u001b[1;32m    129\u001b[0m     element[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m curr_t(element[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     element \u001b[38;5;241m=\u001b[39m \u001b[43mcurr_t\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m element\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/avalanche/benchmarks/utils/transforms.py:279\u001b[0m, in \u001b[0;36mTupleTransform.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m         args_list[idx] \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args_list\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env_name/lib/python3.12/site-packages/torchvision/transforms/functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting experiment...\")\n",
    "results_dict = {}  # Use a dictionary instead of a list\n",
    "for index, experience in enumerate(benchmark.train_stream):\n",
    "    print(\"Start of experience: \", experience.current_experience)\n",
    "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
    "    res = cl_strategy.train(experience)\n",
    "    print(\"Training completed\")\n",
    "    print(\"Computing accuracy on the whole test\")\n",
    "    results_dict[index] = cl_strategy.eval(benchmark.test_stream)  # Use the index as the key\n",
    "\n",
    "print(\"Experiment completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6a51b8-a38c-4c1c-b990-c41f6710c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    file_name = f\"{MODEL_NAME}_{DATASET_NAME}_{RUN}_results.txt\"\n",
    "    file_path = ROOT / DATASET_NAME / MODEL_NAME / RUN / file_name\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(f\"Model: {MODEL_NAME}\\n\")\n",
    "        file.write(f\"Dataset: {DATASET_NAME}\\n\")\n",
    "        file.write(f\"Run: {RUN}\\n\")  \n",
    "        file.write(\"\\nResults Dictionary:\\n\")\n",
    "        file.write(\"--------------------------------------------------\\n\")\n",
    "        for key, value in results_dict.items():\n",
    "            file.write(f\"Experience {key}:\\n\")\n",
    "            for metric, metric_value in value.items():\n",
    "                # Convert tensors to lists for saving\n",
    "                if isinstance(metric_value, torch.Tensor):\n",
    "                    metric_value = metric_value.tolist()\n",
    "                file.write(f\"  {metric}: {metric_value}\\n\")\n",
    "            file.write(\"--------------------------------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_name)",
   "language": "python",
   "name": "env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
